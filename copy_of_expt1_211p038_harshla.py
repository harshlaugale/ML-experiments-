# -*- coding: utf-8 -*-
"""Copy of expt1_211P038_harshla.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ey6sIfQ40EHcorMDHaFBjvOMVtyCbVGq
"""

numbers = [1, 2, 3, 4, 5, 6, 7]
result=[]
for i in numbers:
  result.append(i*i)
print("Squares of the numbers by Harshla Ugale:",result)

def common_element(set1,set2):
  return set1.intersection(set2)

list1 = [1, 2, 3, 4, 5, 6, 7, 8, 9]
list2 = [5, 6, 7, 8, 9, 10, 11, 12, 13]

set1=set(list1)
set2=set(list2)

# Finding common elements by Harshla Ugale
print((sorted(list(common_element(set1,set2)))))

students = [
("Bharti", 88),
("Parth", 75),
("Ronit", 88),
("Sakshi", 93),
("Tirtha", 75)
]
temp=sorted(students,key=lambda x:(-x[1],x[0]))
print("Sorted Students:",temp)

students_scores = {
"Bharti": 88,
"Parth": 75,
"Ronit": 88,
"Sakshi": 93,
"Tirtha": 75
}
max_score=max(students_scores.values())
# List Comprehension
top_scorers=[item for item in students_scores if students_scores[item] == max_score]
print("Top Scorers:",top_scorers)

import numpy as np
def sigmoid(x):
  return 1/(1 + np.exp(-x))

array_input = np.array([-1.0, 0.0, 1.0, 2.0, 3.0])
scalar_input = 0.5

print(f'Sigmoid of scalar input by harshla = {sigmoid(scalar_input)}')
print(f'Sigmoid of array input by harshla =\n {sigmoid(array_input)}')

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
data={
    'customer':[1,2,3,4,5],
    'age':[25,45,np.nan,35,50],
    'gender':['Male','Female','Female',np.nan,'Male'],
    'annual_income':[50000,60000,45000,80000,120000],
    'purchase_amount':[200,150,300,400,np.nan],
    'purchase_date':['2023-01-01','2023-02-15','2023-02-15','2023-02-15','2023-02-15']
}
df=pd.DataFrame(data)
print("Original DataFrame by harshla:\n",df)
# Handling missing values
df['age'].fillna(df['age'].mean(),inplace=True)
df['gender'].fillna(df['gender'].mode()[0],inplace=True)
df['purchase_amount'].fillna(df['purchase_amount'].median(),inplace=True)
print("\nDataFrame after handling missing values:\n",df)
# Encoding categorical variables
df['gender']=df['gender'].map({'Male':0,'Female':1})
print("\nDataFrame after encoding categorical variables:\n",df)
# Normalizing numerical variables
scaler=StandardScaler()
df[['age','annual_income','purchase_amount']]=scaler.fit_transform(df[['age','annual_income','purchase_amount']])
print("\nDataFrame after normalizing numerical variables:\n",df)
# Creating a new features - total purchase amount per customer
df['total_purchase_amount']=df['purchase_amount'].cumsum()
print("\nDataFrame after creating a new feature:\n",df)

import numpy as np
import matplotlib.pyplot as plt

data = {
    'epoch': np.arange(1, 21),
    'train_loss': np.random.uniform(0.2, 0.6, 20),
    'val_loss': np.random.uniform(0.3, 0.7, 20),
    'train_accuracy': np.random.uniform(0.7, 0.95, 20),
    'val_accuracy': np.random.uniform(0.6, 0.9, 20)
}
df = pd.DataFrame(data)
df = df.sort_values('epoch')
plt.figure(figsize = (12, 5))
plt.subplot(1, 2, 1)
plt.plot(df['epoch'],df['train_loss'] ,label = "Train Loss", color = "orange", marker ="o" )
plt.plot(df['epoch'],df['val_loss'] ,label = "Value Loss", color = "blue", marker ="o" )
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Visualization By harshla')
plt.legend()

# Plot 2
plt.subplot(1, 2, 2)
plt.plot(df['epoch'],df['train_accuracy'] ,label = "Train Accuracy", color = "yellow", marker ="o" )
plt.plot(df['epoch'],df['val_accuracy'] ,label = "Value Accuracy", color = "red", marker ="o" )
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training accuracy Visualization By harshla')
plt.legend()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
np.random.seed(0)
# Generate random data
n_samples = 100
age = np.random.randint(18, 70, n_samples)
gender = np.random.choice(['Male', 'Female'], n_samples)
usage_minutes = np.random.randint(100, 1000, n_samples)
churn_status = np.random.choice([0, 1], n_samples, p=[0.8, 0.2])  # 80% not churned, 20% churned
# Create a DataFrame
df = pd.DataFrame({
    'age': age,
    'gender': gender,
    'usage_minutes': usage_minutes,
    'churn_status': churn_status
})
df.to_csv('telecom_data_by_aditya.csv', index=False)
# Draw pair plot
sns.pairplot(df, hue='churn_status')
plt.suptitle('Pair Plot of Telecom Data Visualization By harshla', y=1.02)
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split

data = {
    'mileage': [150000, 30000, 45000, 60000, 75000, 90000, 105000, 120000],
    'price': [15000, 2000, 10000, 8000, 6000, 4000, 3000, 12000]
}
# Convert the dictionary to a pandas DataFrame
df = pd.DataFrame(data)

# Split the dataset into training and test sets
train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)
# Display the training and test sets
print("Training set:\n",train_set)
print("\nTest set:\n",test_set)